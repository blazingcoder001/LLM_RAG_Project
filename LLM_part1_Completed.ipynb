{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAahzI9lcLUr"
   },
   "source": [
    "# Practice: question answering with retrieval\n",
    "\n",
    "In this homework you will build a retrieval-based question answering system, one component at a time.\n",
    "\n",
    "_Okay, realistically, there's like, two components, but technically it's one component at a time._\n",
    "\n",
    "\n",
    "![img](https://www.cs.upc.edu/~mlatifi/index_files/qa-logo.jpg)\n",
    "\n",
    "\n",
    "\n",
    "There are two parts to this type of systems: a retriever and a generator.\n",
    "- the retriever subsystem searches for similar texts from a given databse, e.g. wikipedia\n",
    "- the generator uses the texts found by the retriever to generate an answer in natural language\n",
    "\n",
    "_this seminar is based on original notebook by [Oleg Vasilev](https://github.com/Omrigan/)_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:55:46.329288Z",
     "iopub.status.busy": "2025-05-06T23:55:46.329048Z",
     "iopub.status.idle": "2025-05-06T23:57:05.850240Z",
     "shell.execute_reply": "2025-05-06T23:57:05.849388Z",
     "shell.execute_reply.started": "2025-05-06T23:55:46.329270Z"
    },
    "id": "WDn3WnJa1ZBt",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.3.0\n",
      "    Uninstalling accelerate-1.3.0:\n",
      "      Successfully uninstalled accelerate-1.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:57:05.852146Z",
     "iopub.status.busy": "2025-05-06T23:57:05.851878Z",
     "iopub.status.idle": "2025-05-06T23:57:09.386605Z",
     "shell.execute_reply": "2025-05-06T23:57:09.385589Z",
     "shell.execute_reply.started": "2025-05-06T23:57:05.852117Z"
    },
    "id": "4dtN8dPocLUy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:57:09.387947Z",
     "iopub.status.busy": "2025-05-06T23:57:09.387530Z",
     "iopub.status.idle": "2025-05-06T23:57:09.474998Z",
     "shell.execute_reply": "2025-05-06T23:57:09.474206Z",
     "shell.execute_reply.started": "2025-05-06T23:57:09.387925Z"
    },
    "id": "O9i6aUkxJC56",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # use 'cuda' for any GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ks8AlEVcLUz"
   },
   "source": [
    "### Part 0: the dataset\n",
    "\n",
    "Before we train anything, let's take a look at the question answering data that we can use. There are several popular datasets, e.g. TriviaQA for trivia questions or GSM8K for math. Today's data is Stanford Question Answering Dataset (SQuAD). Given a paragraph of text and a question, our model's task is to select a snippet that answers the question.\n",
    "\n",
    "We are not going to solve the full task today. Instead, we'll train a model to __select the sentence containing answer__ among several options.\n",
    "\n",
    "As usual, you are given an utility module with data reader and some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:57:09.476980Z",
     "iopub.status.busy": "2025-05-06T23:57:09.476765Z",
     "iopub.status.idle": "2025-05-06T23:57:10.873086Z",
     "shell.execute_reply": "2025-05-06T23:57:10.872418Z",
     "shell.execute_reply.started": "2025-05-06T23:57:09.476964Z"
    },
    "id": "MtD9zmBuol1-",
    "outputId": "d19fa473-e059-4c99-bb9d-63cfb46cdd08",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:57:10.874187Z",
     "iopub.status.busy": "2025-05-06T23:57:10.873775Z",
     "iopub.status.idle": "2025-05-06T23:57:35.271815Z",
     "shell.execute_reply": "2025-05-06T23:57:35.270952Z",
     "shell.execute_reply.started": "2025-05-06T23:57:10.874168Z"
    },
    "id": "iWRei-HxcLU0",
    "outputId": "d9ea3b40-4b38-473a-f552-82c90675a1de",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "--2025-05-06 23:57:30--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week_extra/retrieval/data.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3553 (3.5K) [text/plain]\n",
      "Saving to: ‘data.py’\n",
      "\n",
      "data.py             100%[===================>]   3.47K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-05-06 23:57:30 (49.0 MB/s) - ‘data.py’ saved [3553/3553]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet transformers==4.36.2 accelerate==0.24.0 sentencepiece==0.1.99 optimum==1.13.2 auto-gptq==0.4.2\n",
    "# ^-- if this fails, remove the specific version and install latest ones: pip install --update transformers accelerate ...\n",
    "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week_extra/retrieval/data.py -O data.py\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad-v2.0.json 2> log\n",
    "\n",
    "import data\n",
    "# backup download link: https://www.dropbox.com/s/q4fuihaerqr0itj/squad.tar.gz?dl=1\n",
    "train, test = data.build_dataset('./squad-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:57:35.273617Z",
     "iopub.status.busy": "2025-05-06T23:57:35.273016Z",
     "iopub.status.idle": "2025-05-06T23:57:35.278650Z",
     "shell.execute_reply": "2025-05-06T23:57:35.277887Z",
     "shell.execute_reply.started": "2025-05-06T23:57:35.273584Z"
    },
    "id": "KvzzSgVicLU0",
    "outputId": "54cb6c6f-03d6-4251-925b-347a7b030d21",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION Where did Beyonce get her name from? \n",
      "\n",
      "TEXT SENTENCES\n",
      "[ ] Beyoncé Giselle Knowles was born in Houston, Texas, to Celestine Ann \"Tina\" Knowles (née Beyincé), a hairdresser and salon owner, and Mathew Knowles, a Xerox sales manager.\n",
      "[v] Beyoncé's name is a tribute to her mother's maiden name.\n",
      "[ ] Beyoncé's younger sister Solange is also a singer and a former member of Destiny's Child.\n",
      "[ ] Mathew is African-American, while Tina is of Louisiana Creole descent (with African, Native American, French, Cajun, and distant Irish and Spanish ancestry).\n",
      "[ ] Through her mother, Beyoncé is a descendant of Acadian leader Joseph Broussard.\n",
      "[ ] She was raised in a Methodist household.\n"
     ]
    }
   ],
   "source": [
    "pid, question, options, correct_indices, wrong_indices = train.iloc[40]\n",
    "print('QUESTION', question, '\\n')\n",
    "print('TEXT SENTENCES')\n",
    "for i, cand in enumerate(options):\n",
    "    print(['[ ]', '[v]'][i in correct_indices], cand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGxVKpjAcLU1"
   },
   "source": [
    "### Pre-trained BERT\n",
    "_(but you guessed it)_\n",
    "\n",
    "We've already solved quite a few tasks from scratch, training our own embeddings and convolutional/recurrent layers. However, one can often achieve higher quality by using pre-trained models. We will default to the good ol' [BERT](https://arxiv.org/abs/1810.04805), though, you are free to use any [other model](https://huggingface.co/models) as you see fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:57:35.279651Z",
     "iopub.status.busy": "2025-05-06T23:57:35.279299Z",
     "iopub.status.idle": "2025-05-06T23:58:01.223328Z",
     "shell.execute_reply": "2025-05-06T23:58:01.222529Z",
     "shell.execute_reply.started": "2025-05-06T23:57:35.279626Z"
    },
    "id": "iRAdNj2IcLU1",
    "outputId": "4515ddc1-39d4-42fd-c7a1-defb17709d73",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2025-05-06 23:57:40.729822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746575861.048578      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746575861.118349      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f467c24cf23843f8ba3c767bfa30fc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6ec293fe984539bd8d9e799fadc10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce3b2de7b8644d9b00ea29350e08a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90b24e0f34b4b2596f0c7f095aef728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a2a45e5a5c47ecbe33b65a7bfb6be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c6e009d6f84e4582093370e3e71400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d5b8fe85804479b442ab8dc39be8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "\n",
    "model_name = 'sentence-transformers/bert-base-nli-mean-tokens'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:01.224977Z",
     "iopub.status.busy": "2025-05-06T23:58:01.224299Z",
     "iopub.status.idle": "2025-05-06T23:58:01.494320Z",
     "shell.execute_reply": "2025-05-06T23:58:01.493501Z",
     "shell.execute_reply.started": "2025-05-06T23:58:01.224941Z"
    },
    "id": "kAQHqgW_cLU1",
    "outputId": "cf01399b-1f56-4441-8f73-106d7c28284a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# just a reminder: here's how it works\n",
    "dummy_lines = [\n",
    "    \"How old are you?\",                                                 # 0\n",
    "    \"In what mythology do two canines watch over the Chinvat Bridge?\",  # 1\n",
    "    \"I'm sorry, okay, I'm not perfect, but I'm trying.\",                # 2\n",
    "    \"What is your age?\",                                                # 3\n",
    "    \"Beware, for I am fearless, and therefore powerful.\",               # 4\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_tensors = tokenizer(dummy_lines, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    out = bert(**batch_tensors)\n",
    "    token_embs = out.last_hidden_state\n",
    "    cls_embs = out.pooler_output\n",
    "    del out\n",
    "\n",
    "\n",
    "mask = batch_tensors['attention_mask'][..., None].to(torch.float32)\n",
    "naive_phrase_embs = (token_embs * mask).sum(1) / mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:01.495531Z",
     "iopub.status.busy": "2025-05-06T23:58:01.495237Z",
     "iopub.status.idle": "2025-05-06T23:58:01.730422Z",
     "shell.execute_reply": "2025-05-06T23:58:01.729678Z",
     "shell.execute_reply.started": "2025-05-06T23:58:01.495503Z"
    },
    "id": "eYLyOgvzcLU3",
    "outputId": "c64d18e8-5a86-4975-f8d4-e9900c9e5b92",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x78987ceaa650>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('phrase similarity')\n",
    "plt.imshow((naive_phrase_embs @ naive_phrase_embs.t()).cpu().data.numpy(), interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apBCmWWgcLU4"
   },
   "source": [
    "As you can see, __the strongest similarity is between lines 0 and 3__. Indeed they correspond to \"How old are you?\" and \"What is your age?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3qa0HGrcLU4"
   },
   "source": [
    "### Retriever Model (2 points)\n",
    "\n",
    "Our goal for today is to build a model that measures similarity between question and answer. In particular, it maps both question and answer into fixed-size vectors such that:\n",
    "\n",
    "Our model is a pair of $V_q(q)$ and $V_a(a)$ - networks that turn phrases into vectors.\n",
    "\n",
    "__Objective:__ Question vector $V_q(q)$ should be __closer__ to correct answer vectors $V_a(a^+)$ than to incorrect ones $V_a(a^-)$ .\n",
    "\n",
    "Both vectorizers can be anything you wish. For starters, let's use a couple of dense layers on top of the pre-trained encoder.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:01.733035Z",
     "iopub.status.busy": "2025-05-06T23:58:01.732819Z",
     "iopub.status.idle": "2025-05-06T23:58:01.739663Z",
     "shell.execute_reply": "2025-05-06T23:58:01.738963Z",
     "shell.execute_reply.started": "2025-05-06T23:58:01.733019Z"
    },
    "id": "2LnBd1IdcLU4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Vectorizer(nn.Module):\n",
    "    def __init__(self, hid_size=256, bert=bert):\n",
    "        \"\"\" A small feedforward network on top of pre-trained encoder. 2-3 layers should be enough \"\"\"\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.hid_size = hid_size\n",
    "\n",
    "        # define a few layers to be applied on top of pre-trained BERT\n",
    "        # note: please make sure your final layer comes with _linear_ activation\n",
    "        # <YOUR CODE HERE>\n",
    "        # Freeze BERT parameters\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, hid_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    def forward(self, input_phrases):\n",
    "        \"\"\"\n",
    "        Apply vectorizer. Use dropout and any other hacks at will.\n",
    "        :param input_phrases: a list of strings, [batch_size]\n",
    "        :returns: predicted phrase vectors, [batch_size, output_size]\n",
    "\n",
    "        Note: you may want to use dropouts.\n",
    "        if self.training:\n",
    "          <something>\n",
    "\n",
    "        Note 2: you may also want to use with torch.no_grad to avoid training BERT for your first attempts\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # In fact, please DO use at least 10% dropout!\n",
    "        # <YOUR CODE>\n",
    "        # return <...>\n",
    "        with torch.no_grad():\n",
    "            batch = tokenizer(input_phrases, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            outputs = self.bert(**batch)\n",
    "\n",
    "        mask = batch['attention_mask'].unsqueeze(-1).float()\n",
    "        token_embs = outputs.last_hidden_state\n",
    "        phrase_embs = (token_embs * mask).sum(1) / mask.sum(1)\n",
    "\n",
    "        x = self.dropout(phrase_embs)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:01.824085Z",
     "iopub.status.busy": "2025-05-06T23:58:01.823848Z",
     "iopub.status.idle": "2025-05-06T23:58:02.149684Z",
     "shell.execute_reply": "2025-05-06T23:58:02.149092Z",
     "shell.execute_reply.started": "2025-05-06T23:58:01.824067Z"
    },
    "id": "bmlIxPRQcLU5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question_vectorizer = Vectorizer()\n",
    "answer_vectorizer = Vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.150625Z",
     "iopub.status.busy": "2025-05-06T23:58:02.150363Z",
     "iopub.status.idle": "2025-05-06T23:58:02.622889Z",
     "shell.execute_reply": "2025-05-06T23:58:02.622064Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.150603Z"
    },
    "id": "krX1gnD6cLU5",
    "outputId": "7fac570d-9ea8-45b7-953c-2c11819f191f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 256])\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "question_vectorizer.train(False)\n",
    "out1 = question_vectorizer(dummy_lines)\n",
    "print(out1.shape)\n",
    "out2 = question_vectorizer(dummy_lines)\n",
    "assert tuple(out1.shape) == (5, question_vectorizer.hid_size)\n",
    "assert torch.allclose(out1, out2, atol=1e-5, rtol=0), \"Make sure your model disables dropout if training == False\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lUHY7LdcLU5"
   },
   "source": [
    "### Retriever training: minibatches\n",
    "\n",
    "Our model learns on triples $(q, a^+, a^-)$:\n",
    "* q - <b>q</b>uestion\n",
    "* (a+) - correct <b>a</b>nswer\n",
    "* (a-) - wrong <b>a</b>nswer\n",
    "\n",
    "Below you will find a generator that samples such triples from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.624126Z",
     "iopub.status.busy": "2025-05-06T23:58:02.623828Z",
     "iopub.status.idle": "2025-05-06T23:58:02.630403Z",
     "shell.execute_reply": "2025-05-06T23:58:02.629729Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.624102Z"
    },
    "id": "GO64sZ3AcLU6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def iterate_minibatches(data, batch_size, shuffle=True, cycle=False):\n",
    "    \"\"\"\n",
    "    Generates minibatches of triples: {questions, correct answers, wrong answers}\n",
    "    If there are several wrong (or correct) answers, picks one at random.\n",
    "    \"\"\"\n",
    "    indices = np.arange(len(data))\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "        for batch_start in range(0, len(indices), batch_size):\n",
    "            batch_indices = indices[batch_start: batch_start + batch_size]\n",
    "            batch = data.iloc[batch_indices]\n",
    "            questions = batch['question'].values\n",
    "            correct_answers = np.array([\n",
    "                row['options'][random.choice(row['correct_indices'])]\n",
    "                for i, row in batch.iterrows()\n",
    "            ])\n",
    "            wrong_answers = np.array([\n",
    "                row['options'][random.choice(row['wrong_indices'])]\n",
    "                for i, row in batch.iterrows()\n",
    "            ])\n",
    "\n",
    "            yield {\n",
    "                'questions' : questions,\n",
    "                'correct_answers': correct_answers,\n",
    "                'wrong_answers': wrong_answers,\n",
    "            }\n",
    "        if not cycle:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.631465Z",
     "iopub.status.busy": "2025-05-06T23:58:02.631238Z",
     "iopub.status.idle": "2025-05-06T23:58:02.649670Z",
     "shell.execute_reply": "2025-05-06T23:58:02.649015Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.631440Z"
    },
    "id": "wcnGu02BcLU6",
    "outputId": "2be77cf9-828b-4d46-8d3b-863ab5dd5ce7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'questions': array(['Why were many killed in Underground Stations?',\n",
      "       'What is the world of the digimon called?',\n",
      "       'Al-Andalus was an Emirate of which entity?'], dtype=object), 'correct_answers': array(['Noises of battle were muffled and sleep was easier in the deepest stations, but many were killed from direct hits on several stations.',\n",
      "       'According to the stories, they are inhabitants of the \"DigiWorld\", a manifestation of Earth\\'s communication network.',\n",
      "       'Many scholars (including Makdisi) have argued that early medieval universities were influenced by the religious madrasahs in Al-Andalus, the Emirate of Sicily, and the Middle East (during the Crusades).'],\n",
      "      dtype='<U202'), 'wrong_answers': array(['Although many civilians had used them as such during the First World War, the government in 1939 refused to allow the stations to be used as shelters so as not to interfere with commuter and troop travel, and the fears that occupants might refuse to leave.',\n",
      "       '\"Digimon\" are \"Digital Monsters\".',\n",
      "       'Lowe and Yasuhara have recently drawn on the well-documented influences of scholarship from the Islamic world on the universities of Western Europe to call for a reconsideration of the development of higher education, turning away from a concern with local institutional structures to a broader consideration within a global context.'],\n",
      "      dtype='<U333')}\n"
     ]
    }
   ],
   "source": [
    "dummy_batch = next(iterate_minibatches(train.sample(3), 3))\n",
    "print(dummy_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F09wfUH9cLU6"
   },
   "source": [
    "### Retriever training: loss function (2 points)\n",
    "We want our vectorizers to put correct answers closer to question vectors and incorrect answers farther away from them. One way to express this is to use is Pairwise Hinge Loss _(aka Triplet Loss)_.\n",
    "\n",
    "$$ L = \\frac 1N \\underset {q, a^+, a^-} \\sum max(0, \\space \\delta - sim[V_q(q), V_a(a^+)] + sim[V_q(q), V_a(a^-)] )$$\n",
    "\n",
    ", where\n",
    "* sim[a, b] is some similarity function: dot product, cosine or negative distance\n",
    "* δ - loss hyperparameter, e.g. δ=1.0. If sim[a, b] is linear in b, all δ > 0 are equivalent.\n",
    "\n",
    "\n",
    "This reads as __Correct answers must be closer than the wrong ones by at least δ.__\n",
    "\n",
    "![img](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/margin.png)\n",
    "<center>_image: question vector is green, correct answers are blue, incorrect answers are red_</center>\n",
    "\n",
    "\n",
    "Note: in effect, we train a Deep Semantic Similarity Model [DSSM](https://www.microsoft.com/en-us/research/project/dssm/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.650758Z",
     "iopub.status.busy": "2025-05-06T23:58:02.650462Z",
     "iopub.status.idle": "2025-05-06T23:58:02.664636Z",
     "shell.execute_reply": "2025-05-06T23:58:02.664043Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.650736Z"
    },
    "id": "nlV8YSewcLU7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    \"\"\" Dot product as a similarity function \"\"\"\n",
    "    # <YOUR CODE>\n",
    "    # return <...>\n",
    "    return torch.sum(a * b, dim=1)\n",
    "\n",
    "\n",
    "def compute_loss(question_vectors, correct_answer_vectors, wrong_answer_vectors, delta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the triplet loss as per formula above.\n",
    "    Use similarity function above for  sim[a, b]\n",
    "    :param question_vectors: float32[batch_size, vector_size]\n",
    "    :param correct_answer_vectors: float32[batch_size, vector_size]\n",
    "    :param wrong_answer_vectors: float32[batch_size, vector_size]\n",
    "    :returns: loss for every row in batch, float32[batch_size]\n",
    "    Hint: you can compute max(0, *) using torch.relu :)\n",
    "    \"\"\"\n",
    "    # <YOUR CODE>\n",
    "    # return <...>\n",
    "    pos_sim = similarity(question_vectors, correct_answer_vectors)\n",
    "    neg_sim = similarity(question_vectors, wrong_answer_vectors)\n",
    "    print(torch.relu(delta - pos_sim + neg_sim))\n",
    "    return torch.relu(delta - pos_sim + neg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.665741Z",
     "iopub.status.busy": "2025-05-06T23:58:02.665407Z",
     "iopub.status.idle": "2025-05-06T23:58:02.710816Z",
     "shell.execute_reply": "2025-05-06T23:58:02.710120Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.665715Z"
    },
    "id": "pzivm0jqcLU7",
    "outputId": "f59a39f9-0172-482b-e95f-d51b7e6d3c8e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 3.8800])\n"
     ]
    }
   ],
   "source": [
    "dummy_v1 = torch.tensor([[0.1, 0.2, -1], [-1.2, 0.6, 1.0]], dtype=torch.float32)\n",
    "dummy_v2 = torch.tensor([[0.9, 2.1, -6.6], [0.1, 0.8, -2.2]], dtype=torch.float32)\n",
    "dummy_v3 = torch.tensor([[-4.1, 0.1, 1.2], [0.3, -1, -2]], dtype=torch.float32)\n",
    "\n",
    "assert np.allclose(similarity(dummy_v1, dummy_v2).data.numpy(), [7.11, -1.84])\n",
    "assert np.allclose(compute_loss(dummy_v1, dummy_v2, dummy_v3, delta=5.0).data.numpy(), [0.0, 3.88])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc30eCwKcLU7"
   },
   "source": [
    "Once loss is working, let's train our model by our usual means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.716116Z",
     "iopub.status.busy": "2025-05-06T23:58:02.715960Z",
     "iopub.status.idle": "2025-05-06T23:58:02.762949Z",
     "shell.execute_reply": "2025-05-06T23:58:02.761924Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.716103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_recall(questions, correct_answers, wrong_answers):\n",
    "    \"\"\"Compute recall using raw text inputs.\"\"\"\n",
    "    # Ensure inputs are lists of strings\n",
    "    questions = [str(q) for q in questions]\n",
    "    correct_answers = [str(a) for a in correct_answers]\n",
    "    wrong_answers = [str(a) for a in wrong_answers]\n",
    "\n",
    "    # Vectorize within get_recall\n",
    "    v_questions = question_vectorizer(questions)\n",
    "    v_correct = answer_vectorizer(correct_answers)\n",
    "    v_incorrect = answer_vectorizer(wrong_answers)\n",
    "\n",
    "    correct_is_closer = similarity(v_questions, v_correct) > similarity(v_questions, v_incorrect)\n",
    "    recall = torch.mean(correct_is_closer.to(torch.float32)).item()\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.764159Z",
     "iopub.status.busy": "2025-05-06T23:58:02.763915Z",
     "iopub.status.idle": "2025-05-06T23:58:02.928948Z",
     "shell.execute_reply": "2025-05-06T23:58:02.928366Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.764142Z"
    },
    "id": "MOdhf_z4cLU8",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666865348816"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it works\n",
    "get_recall(**dummy_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KArsnvUpcLU9"
   },
   "source": [
    "### Training loop (1 point)\n",
    "\n",
    "Just as we always do, we can now train DSSM on minibatches and periodically measure recall on validation data.\n",
    "\n",
    "\n",
    "__Note 1:__ triplet loss training may be very sensitive to the choice of batch size. Small batch size may decrease model quality because there are less negative to consider.\n",
    "\n",
    "__Note 2:__ here we use the same dataset as __\"test set\"__ and __\"validation (dev) set\"__.\n",
    "\n",
    "In any serious scientific experiment, those must be two separate sets. Validation is for hyperparameter tuning and test is for final eval only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.929868Z",
     "iopub.status.busy": "2025-05-06T23:58:02.929647Z",
     "iopub.status.idle": "2025-05-06T23:58:02.954260Z",
     "shell.execute_reply": "2025-05-06T23:58:02.953463Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.929852Z"
    },
    "id": "gDaKqIdqcLU9",
    "outputId": "8bdac517-fb04-4301-ee25-7b7488f8ae5c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  return disable_fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Initialize model, optimizers, anything else you want\n",
    "# <YOUR CODE HERE>\n",
    "\n",
    "# Initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "question_vectorizer = Vectorizer().to(device)\n",
    "answer_vectorizer = Vectorizer().to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(question_vectorizer.parameters()) + list(answer_vectorizer.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ewma = lambda x, span: pd.DataFrame({'x': x})['x'].ewm(span=span).mean().values\n",
    "dev_batches = iterate_minibatches(test, batch_size=256, cycle=True)\n",
    "loss_history = []\n",
    "dev_recall_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-05-06T23:58:02.955387Z",
     "iopub.status.busy": "2025-05-06T23:58:02.955097Z",
     "iopub.status.idle": "2025-05-07T00:08:42.647266Z",
     "shell.execute_reply": "2025-05-07T00:08:42.645470Z",
     "shell.execute_reply.started": "2025-05-06T23:58:02.955372Z"
    },
    "id": "RuDUsgjrcLU9",
    "outputId": "621e5d42-a777-48ed-a963-7d7b957b6b84",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2207, 1.4062, 0.0000, 0.9888, 0.4439, 1.4489, 0.6832, 0.6900, 0.0000,\n",
      "        1.0042, 0.0000, 0.0000, 0.8859, 0.5267, 0.0000, 1.3539, 0.2838, 1.8072,\n",
      "        0.5619, 0.0000, 1.3102, 0.0000, 0.0000, 0.8596, 0.0000, 0.0000, 0.6405,\n",
      "        0.0000, 0.5737, 0.0000, 0.0000, 0.0000, 0.8108, 0.0000, 0.0000, 2.8297,\n",
      "        4.1464, 0.0000, 0.0000, 0.0000, 1.3861, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 2.8205, 0.2319, 0.0000, 1.0150, 0.0000, 0.0000, 0.5216,\n",
      "        0.9917, 0.1212, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8580, 0.9680,\n",
      "        0.0000, 0.0000, 0.0000, 1.4801, 0.0000, 0.0000, 0.0000, 0.8285, 1.5273,\n",
      "        0.3184, 2.5311, 0.8466, 0.0000, 2.6088, 0.5950, 0.0000, 1.1799, 1.0546,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3508, 0.0000, 0.0000, 0.2092,\n",
      "        0.0000, 0.6119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 2.6226, 1.1616, 0.0000, 0.2172, 0.7493, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4709, 0.7902,\n",
      "        0.0069, 1.3900, 2.0843, 0.0000, 0.0000, 1.1967, 0.0000, 4.3854, 0.0000,\n",
      "        0.0000, 0.5906, 0.4221, 0.0098, 0.2167, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.8285, 0.0000, 0.0000, 0.0000, 0.6332, 0.9085, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4975, 0.0383, 0.0000, 0.0000, 0.0000, 1.1369,\n",
      "        0.0000, 2.5614, 0.0000, 0.0000, 0.8887, 0.0000, 0.0000, 1.5068, 0.0000,\n",
      "        1.5345, 3.1136, 0.0000, 0.0449, 2.1954, 0.0000, 0.0000, 0.1467, 0.0000,\n",
      "        3.3125, 0.0000, 0.0000, 0.5857, 1.1963, 0.0000, 0.3803, 0.0000, 1.7760,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0596, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4514, 2.3058, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.1315, 0.0000, 0.0000, 0.0000, 0.0000, 4.3482,\n",
      "        0.5572, 0.0000, 0.0000, 1.5242, 0.0000, 0.0000, 0.0000, 2.5216, 0.0000,\n",
      "        0.8432, 0.4312, 0.0000, 0.0000, 0.2116, 0.0000, 0.0000, 0.0000, 1.2144,\n",
      "        1.4196, 0.0000, 0.7312, 0.0000, 0.0000, 0.7254, 0.0000, 0.9049, 4.9658,\n",
      "        0.0000, 0.0000, 0.0000, 1.7637, 0.0000, 0.0000, 0.1990, 1.9636, 0.0000,\n",
      "        2.9421, 0.0000, 0.9331, 0.0339, 3.8027, 0.0000, 0.0000, 0.0000, 0.1629,\n",
      "        0.0000, 1.0857, 0.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 2.4488, 0.5759, 0.2768, 0.0000, 2.1935,\n",
      "        0.0000, 2.0527, 0.0000, 0.0000, 1.5265, 0.2625, 0.0000, 0.0000, 0.0000,\n",
      "        1.1765, 0.0000, 0.0000, 0.0000, 1.4826, 0.0000, 1.8818, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0088, 3.2367, 0.0000,\n",
      "        0.7925, 0.9743, 0.0000, 0.0000, 0.0000, 0.0000, 2.0428, 0.0000, 0.0000,\n",
      "        0.5692, 0.0000, 0.0000, 0.0000, 1.6734, 0.0000, 0.2519, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 1.5205, 0.2570, 0.0000, 1.7542, 0.0000, 0.6671, 1.8949,\n",
      "        0.0000, 1.2508, 1.5755, 2.4562, 1.5483, 0.0000, 0.5529, 0.0000, 0.0000,\n",
      "        0.9542, 0.0000, 0.9484, 0.9543, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 1.3008, 0.0000, 0.5627, 0.0000, 1.4914, 0.1483,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.5994, 0.0000, 0.0000, 0.0000, 1.3651,\n",
      "        0.0000, 0.0000, 0.0000, 0.6148, 0.0000, 0.0000, 0.0000, 0.0000, 0.2075,\n",
      "        0.0000, 0.2371, 0.4731, 0.2797, 0.0000, 0.0000, 0.0000, 0.3743, 0.0000,\n",
      "        1.0049, 0.3368, 0.0000, 0.0000, 1.6241, 0.0805, 2.0465, 0.0000, 0.0000,\n",
      "        2.0448, 0.3718, 2.0637, 0.0000, 0.0000, 0.0000, 0.0000, 2.4393, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.2917, 0.6085, 0.1033, 0.0000, 0.0000, 0.6093,\n",
      "        0.1513, 0.0000, 0.0000, 0.0000, 0.0000, 1.3621, 0.1094, 0.1255, 1.1225,\n",
      "        0.0000, 0.3175, 0.0000, 2.8493, 0.8075, 0.0000, 3.8560, 0.0000, 0.2941,\n",
      "        0.0000, 1.7250, 0.0000, 1.4554, 1.7280, 2.4175, 0.0000, 0.6316, 0.4869,\n",
      "        2.2109, 0.0229, 2.1162, 0.0000, 2.0586, 1.8225, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 2.4472, 0.0000, 0.0000, 0.4015, 2.5473, 0.0000, 0.5324, 0.1849,\n",
      "        1.2421, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1533, 0.0000,\n",
      "        0.0000, 0.0000, 1.1578, 1.5096, 0.0000, 0.2501, 0.0000, 0.0000, 0.0000,\n",
      "        0.5319, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5605, 1.1357,\n",
      "        0.0000, 0.0000, 0.4903, 0.0000, 0.0000, 0.9264, 0.0943, 0.0000, 0.4731,\n",
      "        1.4000, 0.0000, 0.2608, 3.0378, 0.2397, 2.4686, 0.8428, 0.0000, 0.0000,\n",
      "        0.0000, 3.9795, 0.0000, 0.0000, 0.0000, 1.4494, 0.0778, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0644, 0.0000, 1.7230, 0.0000, 0.6946, 1.6451, 0.0000,\n",
      "        1.2272, 0.0000, 0.8158, 0.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/883024258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Convert batch['questions'] to a list of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mq_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0ma_pos_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct_answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0ma_neg_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wrong_answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/530069457.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_phrases)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# return <...>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# infinite training loop. Stop it manually or implement early stopping\n",
    "\n",
    "# for batch in iterate_minibatches(train, batch_size=256, cycle=True):\n",
    "for batch_idx, batch in enumerate(iterate_minibatches(train, batch_size=256, cycle=True)):\n",
    "\n",
    "    # # Perform one training step\n",
    "    # <YOUR CODE>\n",
    "\n",
    "\n",
    "    # loss_t = <...>\n",
    "    # loss_history.append(float(loss_t))\n",
    "\n",
    "    # Training step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Vectorize batch\n",
    "    # Convert batch['questions'] to a list of strings\n",
    "    q_vecs = question_vectorizer(batch['questions'].tolist())\n",
    "    a_pos_vecs = answer_vectorizer(batch['correct_answers'].tolist())\n",
    "    a_neg_vecs = answer_vectorizer(batch['wrong_answers'].tolist())\n",
    "\n",
    "    # Compute loss\n",
    "    loss = compute_loss(q_vecs, a_pos_vecs, a_neg_vecs)\n",
    "\n",
    "    # Calculate the mean loss over the batch to get a scalar value\n",
    "    loss = loss.mean()\n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store loss\n",
    "    loss_t = loss.item()\n",
    "    loss_history.append(loss_t)\n",
    "\n",
    "    # Validation every 50 steps\n",
    "    if (batch_idx + 1) % 50 == 0:\n",
    "        \n",
    "        dev_batch = next(dev_batches)\n",
    "        with torch.no_grad():\n",
    "        # Pass raw text to get_recall (no vectorization here)\n",
    "            recall_t = get_recall(\n",
    "                dev_batch['questions'].tolist(), \n",
    "                dev_batch['correct_answers'].tolist(),\n",
    "                dev_batch['wrong_answers'].tolist()\n",
    "            )\n",
    "        dev_recall_history.append(recall_t)\n",
    "\n",
    "        # Update plots\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=[12, 6])\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Train Loss (Hinge)')\n",
    "        plt.grid()\n",
    "        plt.scatter(np.arange(len(loss_history)), loss_history, alpha=0.1)\n",
    "        plt.plot(ewma(loss_history, span=100))\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Validation Recall')\n",
    "        plt.grid()\n",
    "        dev_time = np.arange(1, len(dev_recall_history)+1) * 50\n",
    "        plt.scatter(dev_time, dev_recall_history, alpha=0.1)\n",
    "        plt.plot(dev_time, ewma(dev_recall_history, span=10))\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "execution": {
     "iopub.execute_input": "2025-05-07T00:08:50.242519Z",
     "iopub.status.busy": "2025-05-07T00:08:50.241950Z",
     "iopub.status.idle": "2025-05-07T00:08:50.264510Z",
     "shell.execute_reply": "2025-05-07T00:08:50.263594Z",
     "shell.execute_reply.started": "2025-05-07T00:08:50.242497Z"
    },
    "id": "kYLKsDNKcLU9",
    "outputId": "abe9cb25-6476-49db-de48-7d26be106d92",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall: 0.7630208333333334\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Please train for at least 85% recall on test set. You may need to change vectorizer model for that.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2536160131.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean recall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_recall_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_recall_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Please train for at least 85% recall on test set. \"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                   \u001b[0;34m\"You may need to change vectorizer model for that.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Well done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Please train for at least 85% recall on test set. You may need to change vectorizer model for that."
     ]
    }
   ],
   "source": [
    "print(\"Mean recall:\", np.mean(dev_recall_history[-10:]))\n",
    "assert np.mean(dev_recall_history[-10:]) > 0.85, \"Please train for at least 85% recall on test set. \"\\\n",
    "                                                  \"You may need to change vectorizer model for that.\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "YMsVSsaScLU-",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Retriever evaluation (2 point)\n",
    "\n",
    "Let's see how well does our model perform on actual question answering.\n",
    "\n",
    "Given a question and a set of possible answers, pick answer with highest similarity to estimate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:08:56.882037Z",
     "iopub.status.busy": "2025-05-07T00:08:56.881762Z",
     "iopub.status.idle": "2025-05-07T00:08:56.886828Z",
     "shell.execute_reply": "2025-05-07T00:08:56.886159Z",
     "shell.execute_reply.started": "2025-05-07T00:08:56.882018Z"
    },
    "id": "drbFaxidcLU-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# optional: any additional preparations, e.g. build index\n",
    "# <...>\n",
    "\n",
    "def select_best_answer(question, possible_answers):\n",
    "    \"\"\"\n",
    "    Predicts which answer best fits the question\n",
    "    :param question: a single string containing a question\n",
    "    :param possible_answers: a list of strings containing possible answers\n",
    "    :returns: integer - the index of best answer in possible_answer\n",
    "    \"\"\"\n",
    "    # <YOUR CODE>\n",
    "    # return <...>\n",
    "    question_vectorizer.eval()\n",
    "    answer_vectorizer.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Vectorize question\n",
    "        q_vec = question_vectorizer([question]).squeeze(0)\n",
    "\n",
    "        # Vectorize all possible answers\n",
    "        a_vecs = answer_vectorizer(possible_answers)\n",
    "\n",
    "        # Compute dot product similarities\n",
    "        similarities = (a_vecs * q_vec).sum(dim=1)\n",
    "\n",
    "        # Return index of maximum similarity\n",
    "        return torch.argmax(similarities).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "execution": {
     "iopub.execute_input": "2025-05-07T00:09:01.480981Z",
     "iopub.status.busy": "2025-05-07T00:09:01.480386Z",
     "iopub.status.idle": "2025-05-07T00:21:11.618877Z",
     "shell.execute_reply": "2025-05-07T00:21:11.618094Z",
     "shell.execute_reply.started": "2025-05-07T00:09:01.480958Z"
    },
    "id": "9aLwahCxcLU-",
    "outputId": "fa1db851-47da-4037-babc-d02c96f2c1c1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26970/26970 [12:10<00:00, 36.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "we need more accuracy!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/60879639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %0.5f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"we need more accuracy!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Great job!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: we need more accuracy!"
     ]
    }
   ],
   "source": [
    "predicted_answers = [\n",
    "    select_best_answer(question, possible_answers)\n",
    "    for i, (question, possible_answers) in tqdm(test[['question', 'options']].iterrows(), total=len(test))\n",
    "]\n",
    "\n",
    "accuracy = np.mean([\n",
    "    answer in correct_ix\n",
    "    for answer, correct_ix in zip(predicted_answers, test['correct_indices'].values)\n",
    "])\n",
    "print(\"Accuracy: %0.5f\" % accuracy)\n",
    "assert accuracy > 0.65, \"we need more accuracy!\"\n",
    "print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:21:15.571426Z",
     "iopub.status.busy": "2025-05-07T00:21:15.571152Z",
     "iopub.status.idle": "2025-05-07T00:21:15.576175Z",
     "shell.execute_reply": "2025-05-07T00:21:15.575462Z",
     "shell.execute_reply.started": "2025-05-07T00:21:15.571404Z"
    },
    "id": "w3ODWG4kcLU_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def draw_results(question, possible_answers, predicted_index, correct_indices):\n",
    "    print(\"Q:\", question, end='\\n\\n')\n",
    "    for i, answer in enumerate(possible_answers):\n",
    "        print(\"#%i: %s %s\" % (i, '[*]' if i == predicted_index else '[ ]', answer))\n",
    "\n",
    "    print(\"\\nVerdict:\", \"CORRECT\" if predicted_index in correct_indices else \"INCORRECT\",\n",
    "          \"(ref: %s)\" % correct_indices, end='\\n' * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-07T00:21:19.292673Z",
     "iopub.status.busy": "2025-05-07T00:21:19.291862Z",
     "iopub.status.idle": "2025-05-07T00:21:19.299070Z",
     "shell.execute_reply": "2025-05-07T00:21:19.298277Z",
     "shell.execute_reply.started": "2025-05-07T00:21:19.292639Z"
    },
    "id": "sLbpRSSmcLU_",
    "outputId": "86ff1ab7-a2c2-4bf7-fbc7-a65fc6e11b63",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Which three countries did Beyonce's song \"Work It Out\" achieve top ten status?\n",
      "\n",
      "#0: [*] In July 2002, Beyoncé continued her acting career playing Foxxy Cleopatra alongside Mike Myers in the comedy film, Austin Powers in Goldmember, which spent its first weekend atop the US box office and grossed $73 million.\n",
      "#1: [ ] Beyoncé released \"Work It Out\" as the lead single from its soundtrack album which entered the top ten in the UK, Norway, and Belgium.\n",
      "#2: [ ] In 2003, Beyoncé starred opposite Cuba Gooding, Jr., in the musical comedy The Fighting Temptations as Lilly, a single mother whom Gooding's character falls in love with.\n",
      "#3: [ ] The film received mixed reviews from critics but grossed $30 million in the U.S. Beyoncé released \"Fighting Temptation\" as the lead single from the film's soundtrack album, with Missy Elliott, MC Lyte, and Free which was also used to promote the film.\n",
      "#4: [ ] Another of Beyoncé's contributions to the soundtrack, \"Summertime\", fared better on the US charts.\n",
      "\n",
      "Verdict: INCORRECT (ref: [1])\n",
      "\n",
      "\n",
      "Q: Jay Z has a website called what?\n",
      "\n",
      "#0: [*] On January 7, 2012, Beyoncé gave birth to a daughter, Blue Ivy Carter, at Lenox Hill Hospital in New York under heavy security.\n",
      "#1: [ ] Two days later, Jay Z released \"Glory\", a song dedicated to their child, on his website Lifeandtimes.com.\n",
      "#2: [ ] The song detailed the couple's pregnancy struggles, including a miscarriage Beyoncé suffered before becoming pregnant with Blue Ivy.\n",
      "#3: [ ] Blue Ivy's cries are included at the end of the song, and she was officially credited as \"B.I.C.\"\n",
      "#4: [ ] on it. At two days old, she became the youngest person ever to appear on a Billboard chart when \"Glory\" debuted on the Hot R&B/Hip-Hop Songs chart.\n",
      "\n",
      "Verdict: INCORRECT (ref: [1])\n",
      "\n",
      "\n",
      "Q: In what year did the state of New York pass a law to free the slaves?\n",
      "\n",
      "#0: [*] Under New York State's gradual abolition act of 1799, children of slave mothers were born to be eventually liberated but were held in indentured servitude until their mid-to-late twenties.\n",
      "#1: [ ] Together with slaves freed by their masters after the Revolutionary War and escaped slaves, a significant free-black population gradually developed in Manhattan.\n",
      "#2: [ ] Under such influential United States founders as Alexander Hamilton and John Jay, the New York Manumission Society worked for abolition and established the African Free School to educate black children.\n",
      "#3: [ ] It was not until 1827 that slavery was completely abolished in the state, and free blacks struggled afterward with discrimination.\n",
      "#4: [ ] New York interracial abolitionist activism continued; among its leaders were graduates of the African Free School.\n",
      "#5: [ ] The city's black population reached more than 16,000 in 1840.\n",
      "\n",
      "Verdict: CORRECT (ref: [0])\n",
      "\n",
      "\n",
      "Q: How many Special Police protected the relay event?\n",
      "\n",
      "#0: [ ] Malaysia: The event was held in the capital city, Kuala Lumpur, on April 21.\n",
      "#1: [ ] The 16.5 km long-relay began from the historic Independence Square, passed in front of several city landmarks before coming to an end at the iconic Petronas Twin Towers.\n",
      "#2: [ ] Among the landmarks the Olympic flame passed next to were the Parliament House, National Mosque, KL Tower and Merdeka Stadium.\n",
      "#3: [*] A team of 1000 personnel from the Malaysian police Special Action Squad guarded the event and escorted the torchbearers.\n",
      "#4: [ ] The last time an Olympic torch relay was held in Malaysia was the 1964 Tokyo edition.\n",
      "\n",
      "Verdict: CORRECT (ref: [3])\n",
      "\n",
      "\n",
      "Q: When the Soviet Union ended in 1991, what was the RSFSR government called?\n",
      "\n",
      "#0: [ ] The Government was known officially as the Council of People's Commissars (1917–1946), Council of Ministers (1946–1978) and Council of Ministers–Government (1978–1991).\n",
      "#1: [*] The first government was headed by Vladimir Lenin as \"Chairman of the Council of People's Commissars of the Russian SFSR\" and the last by Boris Yeltsin as both head of government and head of state under the title \"President\".\n",
      "\n",
      "Verdict: INCORRECT (ref: [0])\n",
      "\n",
      "\n",
      "Q: What radio station format is facing demographic pressures in the present day?\n",
      "\n",
      "#0: [*] The soft AC format may soon be facing the demographic pressures that the jazz and big band formats faced in the 1960s and 1970s and that the oldies format is starting to face today, with the result that one may hear soft AC less on over-the-air radio and more on satellite radio systems in coming years.\n",
      "#1: [ ] Much of the music and artists that were traditionally played on soft AC stations have been relegated to the adult standards format, which is itself disappearing because of aging demographics.\n",
      "#2: [ ] Some soft AC stations have found a niche by incorporating more oldies into their playlists and are more open to playing softer songs that fit the \"traditional\" definition of AC.\n",
      "\n",
      "Verdict: CORRECT (ref: [0])\n",
      "\n",
      "\n",
      "Q: Where was the street named after Tito that was found unconstitutional located?\n",
      "\n",
      "#0: [ ] In the years following the dissolution of Yugoslavia, some historians stated that human rights were suppressed in Yugoslavia under Tito, particularly in the first decade up until the Tito-Stalin split.\n",
      "#1: [*] On 4 October 2011, the Slovenian Constitutional Court found a 2009 naming of a street in Ljubljana after Tito to be unconstitutional.\n",
      "#2: [ ] While several public areas in Slovenia (named during the Yugoslav period) do already bear Tito's name, on the issue of renaming an additional street the court ruled that:\n",
      "\n",
      "Verdict: CORRECT (ref: [1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 100, 1000, 2000, 3000, 4000, 5000]:\n",
    "    draw_results(test.iloc[i].question, test.iloc[i].options,\n",
    "                 predicted_answers[i], test.iloc[i].correct_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-07T00:21:27.572863Z",
     "iopub.status.busy": "2025-05-07T00:21:27.572585Z",
     "iopub.status.idle": "2025-05-07T00:21:27.602925Z",
     "shell.execute_reply": "2025-05-07T00:21:27.602343Z",
     "shell.execute_reply.started": "2025-05-07T00:21:27.572841Z"
    },
    "id": "Ki4qVJo_cLU_",
    "outputId": "7796305d-d224-434e-c475-292d7d038a93",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is my name?\n",
      "\n",
      "#0: [ ] Names are typically given at birth\n",
      "#1: [*] Your name is specified in your birth certificate\n",
      "#2: [ ] Personal names vary across cultures\n",
      "\n",
      "Verdict: INCORRECT (ref: [0])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What is my name?\" # your question here!\n",
    "possible_answers = [\n",
    "    # <...>\n",
    "    # # ^- your options.\n",
    "    \"Names are typically given at birth\",\n",
    "    \"Your name is specified in your birth certificate\",\n",
    "    \"Personal names vary across cultures\"\n",
    "]\n",
    "predicted_answer = select_best_answer(question, possible_answers)\n",
    "\n",
    "draw_results(question, possible_answers,\n",
    "             predicted_answer, [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw0l5dyAcLU_"
   },
   "source": [
    "### Part 2: to prompt a generator (3 points)\n",
    "\n",
    "You have built a model that can select the most relevant sentence from a text document. However, this is still not the same as question answering - at least not how humans understand it. The full question answering system shoud answer your question in a dialogue - and perhap even let you ask follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arP5tXkatT5M",
    "outputId": "10f81230-6df5-4cf8-b1cc-6fa19849757f",
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:26:14.228218Z",
     "iopub.status.busy": "2025-05-07T00:26:14.227926Z",
     "iopub.status.idle": "2025-05-07T00:26:14.865344Z",
     "shell.execute_reply": "2025-05-07T00:26:14.864735Z",
     "shell.execute_reply.started": "2025-05-07T00:26:14.228197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save({\n",
    "    'question_state_dict': question_vectorizer.state_dict(),\n",
    "    'answer_state_dict': answer_vectorizer.state_dict(),\n",
    "    'hidden_size': question_vectorizer.hid_size,\n",
    "    'tokenizer': tokenizer  # Save tokenizer if using custom one\n",
    "}, '/kaggle/working/retriever_model.pth')  # Save in Kaggle working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T00:08:42.659425Z",
     "iopub.status.idle": "2025-05-07T00:08:42.659720Z",
     "shell.execute_reply": "2025-05-07T00:08:42.659609Z",
     "shell.execute_reply.started": "2025-05-07T00:08:42.659596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#For loading retriever\n",
    "# checkpoint = torch.load(filename, map_location=device)\n",
    "# model = Vectorizer(hid_size=checkpoint['hidden_size']).to(device)\n",
    "# model.question_vectorizer.load_state_dict(checkpoint['question_state_dict'])\n",
    "# model.answer_vectorizer.load_state_dict(checkpoint['answer_state_dict'])    \n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:26:58.787034Z",
     "iopub.status.busy": "2025-05-07T00:26:58.786757Z",
     "iopub.status.idle": "2025-05-07T00:28:02.686161Z",
     "shell.execute_reply": "2025-05-07T00:28:02.685546Z",
     "shell.execute_reply.started": "2025-05-07T00:26:58.787016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.35.0\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting auto-gptq==0.7.1\n",
      "  Downloading auto_gptq-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting optimum==1.16.0\n",
      "  Downloading optimum-1.16.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (2.32.3)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.35.0)\n",
      "  Downloading tokenizers-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.0) (4.67.1)\n",
      "Collecting accelerate>=0.26.0 (from auto-gptq==0.7.1)\n",
      "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from auto-gptq==0.7.1) (3.5.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from auto-gptq==0.7.1) (0.1.99)\n",
      "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (from auto-gptq==0.7.1) (1.0.1)\n",
      "Collecting gekko (from auto-gptq==0.7.1)\n",
      "  Downloading gekko-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from auto-gptq==0.7.1) (2.5.1+cu124)\n",
      "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from auto-gptq==0.7.1) (0.14.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from optimum==1.16.0) (15.0.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from optimum==1.16.0) (1.13.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->auto-gptq==0.7.1) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.35.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.35.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.35.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.35.0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.35.0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.35.0) (2.4.1)\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.35.0)\n",
      "  Downloading tokenizers-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting peft>=0.5.0 (from auto-gptq==0.7.1)\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.15.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.13.1-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading peft-0.8.1-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading peft-0.8.0-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading peft-0.6.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting accelerate>=0.26.0 (from auto-gptq==0.7.1)\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.0)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is looking at multiple versions of peft to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->auto-gptq==0.7.1) (3.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->optimum==1.16.0) (1.3.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.16.0) (3.20.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->optimum==1.16.0) (10.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->auto-gptq==0.7.1) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->auto-gptq==0.7.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->auto-gptq==0.7.1) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->auto-gptq==0.7.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->auto-gptq==0.7.1) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->auto-gptq==0.7.1) (3.11.16)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->auto-gptq==0.7.1)\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets->auto-gptq==0.7.1)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting datasets (from auto-gptq==0.7.1)\n",
      "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.0) (2025.1.31)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge->auto-gptq==0.7.1) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->auto-gptq==0.7.1) (1.19.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->auto-gptq==0.7.1) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.35.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.35.0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.35.0) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.35.0) (2024.2.0)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->auto-gptq==0.7.1)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->auto-gptq==0.7.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->auto-gptq==0.7.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->auto-gptq==0.7.1) (2025.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.35.0) (2024.2.0)\n",
      "Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading auto_gptq-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optimum-1.16.0-py3-none-any.whl (403 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.4/403.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gekko-1.3.0-py3-none-any.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, huggingface-hub, tokenizers, transformers, accelerate, peft, gekko, datasets, optimum, auto-gptq\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.30.2\n",
      "    Uninstalling huggingface-hub-0.30.2:\n",
      "      Successfully uninstalled huggingface-hub-0.30.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.2\n",
      "    Uninstalling transformers-4.36.2:\n",
      "      Successfully uninstalled transformers-4.36.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.24.0\n",
      "    Uninstalling accelerate-0.24.0:\n",
      "      Successfully uninstalled accelerate-0.24.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.5.0\n",
      "    Uninstalling datasets-3.5.0:\n",
      "      Successfully uninstalled datasets-3.5.0\n",
      "  Attempting uninstall: optimum\n",
      "    Found existing installation: optimum 1.13.2\n",
      "    Uninstalling optimum-1.13.2:\n",
      "      Successfully uninstalled optimum-1.13.2\n",
      "  Attempting uninstall: auto-gptq\n",
      "    Found existing installation: auto-gptq 0.4.2\n",
      "    Uninstalling auto-gptq-0.4.2:\n",
      "      Successfully uninstalled auto-gptq-0.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\n",
      "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\n",
      "diffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.0 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.32.1 auto-gptq-0.7.1 datasets-2.14.7 dill-0.3.7 fsspec-2023.10.0 gekko-1.3.0 huggingface-hub-0.17.3 multiprocess-0.70.15 optimum-1.16.0 peft-0.13.2 pyarrow-hotfix-0.7 tokenizers-0.14.1 transformers-4.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:410: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/usr/local/lib/python3.11/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:418: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/usr/local/lib/python3.11/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd(cast_inputs=torch.float16)\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf2ea3b20874e1ea339c12b13c1fe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.\n",
      "WARNING - CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:\n",
      "1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n",
      "2. You are using pytorch without CUDA support.\n",
      "3. CUDA and nvcc are not installed in your device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63184c5407d45be9ad0c14f3dc3613b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "quantize_config.json:   0%|          | 0.00/186 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e31d2471e145f29bb938c628f968d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - The layer lm_head is not quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1187 [00:00<?, ?w/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0461c222494b22a4b1ad68c876df2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aae7842957e43cabc4600f6e8b24e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ba10133898440a9b9a4d1c77300f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c137ea04c9f84f14a60a783734d25804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "!pip install -U transformers==4.35.0 auto-gptq==0.7.1 optimum==1.16.0\n",
    "\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'TheBloke/Mistral-7B-Instruct-v0.2-GPTQ'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load with AutoGPTQ's optimized loader\n",
    "model = AutoGPTQForCausalLM.from_quantized(\n",
    "    model_name,\n",
    "    use_safetensors=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    inject_fused_attention=False  # Disable problematic fused attention\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:29:04.101710Z",
     "iopub.status.busy": "2025-05-07T00:29:04.100949Z",
     "iopub.status.idle": "2025-05-07T00:29:04.107377Z",
     "shell.execute_reply": "2025-05-07T00:29:04.106698Z",
     "shell.execute_reply.started": "2025-05-07T00:29:04.101682Z"
    },
    "id": "3b_lFbiPcLVA",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION What was the first album Beyoncé released as a solo artist? \n",
      "\n",
      "TEXT SENTENCES\n",
      "[ ] Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress.\n",
      "[ ] Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child.\n",
      "[ ] Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time.\n",
      "[v] Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n"
     ]
    }
   ],
   "source": [
    "pid, question, options, correct_indices, wrong_indices = train.iloc[10]\n",
    "print('QUESTION', question, '\\n')\n",
    "print('TEXT SENTENCES')\n",
    "for i, cand in enumerate(options):\n",
    "    print(['[ ]', '[v]'][i in correct_indices], cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:29:10.287546Z",
     "iopub.status.busy": "2025-05-07T00:29:10.287264Z",
     "iopub.status.idle": "2025-05-07T00:29:40.179224Z",
     "shell.execute_reply": "2025-05-07T00:29:40.178598Z",
     "shell.execute_reply.started": "2025-05-07T00:29:10.287526Z"
    },
    "id": "bhQ9r0RycLVA",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What was the first album Beyoncé released as a solo artist?\n",
      "Generated Answer: The first album Beyoncé released as a solo artist was \"Dangerously in Love\" in 2003.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_answer_with_context(question, context_sentences):\n",
    "    \"\"\"Generate answer using LLM with retrieved context\"\"\"\n",
    "    # Format context\n",
    "    context_str = \"\\n\".join([\n",
    "        f\"{i+1}. {sentence}\"\n",
    "        for i, sentence in enumerate(context_sentences)\n",
    "    ])\n",
    "\n",
    "    # Create prompt using chat template\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Answer questions using ONLY the provided context. Keep answers concise.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Understood! Please provide the question and context.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\\nContext:\\n{context_str}\"}\n",
    "    ]\n",
    "\n",
    "    # Tokenize and generate\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs=input_ids,  # Changed to keyword argument\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "# Example usage with data from dataset\n",
    "pid, question, options, correct_indices, wrong_indices = train.iloc[10]\n",
    "\n",
    "# Get relevant context using our retriever\n",
    "context_sentences = [options[i] for i in correct_indices]\n",
    "\n",
    "# Generate final answer\n",
    "answer = generate_answer_with_context(question, context_sentences)\n",
    "print(\"Question:\", question)\n",
    "print(\"Generated Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35yibHtVcLVB"
   },
   "source": [
    "### Optional tasks for bonus points\n",
    "\n",
    "There are many ways to improve our question answering model. Here's a bunch of things you can do to increase your understanding and get bonus points.\n",
    "\n",
    "### 1.  Hard Negatives (2+ pts)\n",
    "\n",
    "Not all wrong answers are equally wrong. As the training progresses, _most negative examples $a^-$ will be to easy._ So easy in fact, that loss function and gradients on such negatives is exactly __0.0__. To improve training efficiency, one can __mine hard negative samples__.\n",
    "\n",
    "Given a list of answers,\n",
    "* __Hard negative__ is the wrong answer with highest similarity with question,\n",
    "\n",
    "$$a^-_{hard} = \\underset {a^-} {argmax} \\space sim[V_q(q), V_a(a^-)]$$\n",
    "\n",
    "* __Semi-hard negative__ is the one with highest similarity _among wrong answers that are farther than positive one. This option is more useful if some wrong answers may actually be mislabelled correct answers.\n",
    "\n",
    "* One can also __sample__ negatives proportionally to $$P(a^-_i) \\sim e ^ {sim[V_q(q), V_a(a^-_i)]}$$\n",
    "\n",
    "\n",
    "The task is to implement at least __hard negative__ sampling and apply it for model training.\n",
    "\n",
    "\n",
    "### 2. Better prompting (2+ pts)\n",
    "\n",
    "In the previous example, we manually engineer a prompt for an LLM to solve produce an answer. However, by this point you know multiple ways to make LLM do your bidding. In this assignment, you should try at least some of them:\n",
    "- try few-shot learning with several handcrafted examples (or hand-picked model inputs)\n",
    "- compare several instruct and/or non-instruct models; for non-instruct models\n",
    "  - please not that you should not use apply_chat_template for non-instruct models\n",
    "- provide some means of quality evaluation to compare your approach against the default one\n",
    "\n",
    "At the minimum, several (10-20) side-by-side examples would do the trick. However, we'd appreciate creative means of evaluation here (crowdsourcing, asking another LM, anything exotic as long as you can explain it).\n",
    "\n",
    "### 3. Search engine (3+ pts)\n",
    "\n",
    "Our basic model only selects answers from 2-5 available sentences in paragraph. You can extend it to search over __the whole dataset__. All sentences in all other paragraphs are viable answers.\n",
    "\n",
    "The goal is to train such a model and use it to __quickly find top-10 answers from the whole set__.\n",
    "\n",
    "* You can ask such model a question of your own making - to see which answers it can find among the entire training dataset or even the entire wikipedia.\n",
    "* Searching for top-K neighbors is easier if you use specialized methods: [KD-Tree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html) or [HNSW](https://github.com/nmslib/hnswlib).\n",
    "* This task is much easier to train if you use hard or semi-hard negatives. You can even find hard negatives for one question from correct answers to other questions in batch - do so in-graph for maximum efficiency. See [1.] for more details.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
